{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b71cb074-abfb-4ff6-9566-58bbde1712d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Llamar API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a4fc9372-8dc0-4084-b1b0-1658a0681c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ts  rh-surface  pressure-surface  gust-surface  \\\n",
      "0  1762030800000   85.967313     101595.992700      2.515978   \n",
      "1  1762041600000   85.142830     101253.756415      2.035879   \n",
      "2  1762052400000   86.719535     101782.316505      2.843617   \n",
      "3  1762063200000   87.485448     101578.533798      2.484131   \n",
      "4  1762074000000   91.928000     101733.660089      2.478069   \n",
      "\n",
      "   past3hprecip-surface  cape-surface  lclouds-surface  \\\n",
      "0              0.002059      0.000000        31.147870   \n",
      "1              0.003753     45.976556        17.475907   \n",
      "2              0.000000      0.000000         8.844894   \n",
      "3              0.003301    455.176793         0.489595   \n",
      "4              0.000000     76.957666         6.763744   \n",
      "\n",
      "   past3hconvprecip-surface                                            warning  \n",
      "0                  0.001782  The testing API version is for development pur...  \n",
      "1                  0.000165  The testing API version is for development pur...  \n",
      "2                  0.000175  The testing API version is for development pur...  \n",
      "3                  0.000721  The testing API version is for development pur...  \n",
      "4                  0.000000  The testing API version is for development pur...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "lat = 4.57937\n",
    "lon = -74.21682\n",
    "api_key = 'SBUdfKRVGJEmElRKmmHGGHgC4nTSzgH2'\n",
    "\n",
    "url = 'https://api.windy.com/api/point-forecast/v2'\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "payload = {\n",
    "    \"lat\": lat,\n",
    "    \"lon\": lon,\n",
    "    \"model\": \"gfs\",\n",
    "    \"parameters\": [\n",
    "        'rh', 'pressure', 'windGust', 'precip', \n",
    "        'cape', 'lclouds', 'convPrecip' \n",
    "    ],\n",
    "    \"levels\": [\"surface\"],\n",
    "    \"key\": api_key\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame({k: v for k, v in data.items() if k != 'units'})\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"Error:\", response.status_code)\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb6beb9-0022-4da9-97c8-fa4e911cf69c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Generar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "bed2750b-0f0c-4b0b-b513-551257559d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el dato base real\n",
    "base = pd.read_csv('dato_base_normal.csv')\n",
    "\n",
    "# Asegurar que tenga las columnas esperadas\n",
    "columnas_modelo = [\n",
    "    'past3hprecip-surface',\n",
    "    'past3hconvprecip-surface',\n",
    "    'rh-surface',\n",
    "    'pressure-surface',\n",
    "    'gust-surface',\n",
    "    'cape-surface',\n",
    "    'lclouds-surface'\n",
    "]\n",
    "\n",
    "base = base[columnas_modelo]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Funci√≥n para perturbar el dato base y simular inundaci√≥n\n",
    "def simular_inundacion(base, n=500):\n",
    "    simulados = []\n",
    "    for _ in range(n):\n",
    "        punto = base.iloc[0].copy()\n",
    "        punto['past3hprecip-surface'] = np.random.uniform(0.2, 0.5)  # lluvia intensa\n",
    "        punto['past3hconvprecip-surface'] = np.random.uniform(0.2, 0.5)\n",
    "        punto['rh-surface'] = np.random.uniform(95, 100)  # saturaci√≥n\n",
    "        punto['pressure-surface'] = np.random.uniform(95000, 97000)  # presi√≥n baja\n",
    "        punto['gust-surface'] = np.random.uniform(8, 15)  # r√°fagas fuertes\n",
    "        punto['cape-surface'] = np.random.uniform(400, 1000)  # alta inestabilidad\n",
    "        punto['lclouds-surface'] = np.random.uniform(80, 100)  # cielo cubierto\n",
    "        punto['inundacion'] = 1\n",
    "        simulados.append(punto)\n",
    "    return pd.DataFrame(simulados)\n",
    "\n",
    "def simular_normales(base, n=500):\n",
    "    simulados = []\n",
    "    for _ in range(n):\n",
    "        punto = base.iloc[0].copy()\n",
    "        punto['past3hprecip-surface'] = np.random.uniform(0.0, 0.001)\n",
    "        punto['past3hconvprecip-surface'] = np.random.uniform(0.0, 0.001)\n",
    "        punto['rh-surface'] = np.random.uniform(30, 60)\n",
    "        punto['pressure-surface'] = np.random.uniform(99500, 102000)\n",
    "        punto['gust-surface'] = np.random.uniform(0, 1.5)\n",
    "        punto['cape-surface'] = np.random.uniform(0, 20)\n",
    "        punto['lclouds-surface'] = np.random.uniform(0, 20)\n",
    "        punto['inundacion'] = 0\n",
    "        simulados.append(punto)\n",
    "    return pd.DataFrame(simulados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "292bd63b-1a64-4e9f-9a86-c2b8b7114157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset final guardado como dataset_entrenamiento_inundacion.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar ambos archivos\n",
    "normales = pd.read_csv('datos_simulados_normales.csv')\n",
    "inundacion = pd.read_csv('datos_simulados_inundacion.csv')\n",
    "\n",
    "# Unirlos en un solo DataFrame\n",
    "df_completo = pd.concat([normales, inundacion], ignore_index=True)\n",
    "\n",
    "# Mezclar aleatoriamente las filas\n",
    "df_completo = df_completo.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Guardar dataset final\n",
    "df_completo.to_csv('dataset_entrenamiento_inundacion.csv', index=False)\n",
    "print(\"‚úÖ Dataset final guardado como dataset_entrenamiento_inundacion.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43bc988-ef58-411f-9667-804196b0f652",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "f9aa4c1d-9a44-49d5-95eb-a824a1a491d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Accuracy en test: 1.000\n",
      "‚úÖ Modelo reentrenado y guardado como modelo_inundacion.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Generar dataset completo\n",
    "df = pd.concat([\n",
    "    simular_normales(base, n=500),\n",
    "    simular_inundacion(base, n=500)\n",
    "], ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "X = df[columnas_modelo]\n",
    "y = df['inundacion']\n",
    "\n",
    "# Entrenamiento\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "pipe_svc = make_pipeline(StandardScaler(), SVC(probability=True))\n",
    "pipe_svc.fit(X_train, y_train)\n",
    "\n",
    "# Evaluaci√≥n\n",
    "print(f\"‚úÖ Accuracy en test: {pipe_svc.score(X_test, y_test):.3f}\")\n",
    "\n",
    "# Guardar modelo\n",
    "joblib.dump(pipe_svc, 'modelo_inundacion.pkl')\n",
    "print(\"‚úÖ Modelo reentrenado y guardado como modelo_inundacion.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be78762-2edb-47fb-9f5f-773ba5fadfb5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Predicci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "6ff3454e-2306-442b-9e4d-0ef449e76245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad de inundaci√≥n en La Maria (4.597956, -74.201885): 0.27\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# === 1. Par√°metros de ubicaci√≥n y API ===\n",
    "# La Mar√≠a\n",
    "lat = 4.597956\n",
    "lon = -74.201885\n",
    "api_key = 'SBUdfKRVGJEmElRKmmHGGHgC4nTSzgH2'\n",
    "\n",
    "url = 'https://api.windy.com/api/point-forecast/v2'\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "parameters = ['rh', 'pressure', 'windGust', 'precip', 'cape', 'lclouds', 'convPrecip']\n",
    "levels = ['surface']\n",
    "\n",
    "payload = {\n",
    "    \"lat\": lat,\n",
    "    \"lon\": lon,\n",
    "    \"model\": \"gfs\",\n",
    "    \"parameters\": parameters,\n",
    "    \"levels\": levels,\n",
    "    \"key\": api_key\n",
    "}\n",
    "\n",
    "# === 2. Consultar Windy API ===\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "\n",
    "    # === 3. Crear DataFrame con nombres originales del API ===\n",
    "    df_raw = pd.DataFrame({k: v for k, v in data.items() if k != 'units'})\n",
    "\n",
    "    # === 4. Renombrar columnas para que coincidan con el modelo entrenado ===\n",
    "    renombrar = {\n",
    "        'precip': 'past3hprecip-surface',\n",
    "        'convPrecip': 'past3hconvprecip-surface',\n",
    "        'rh': 'rh-surface',\n",
    "        'pressure': 'pressure-surface',\n",
    "        'windGust': 'gust-surface',\n",
    "        'cape': 'cape-surface',\n",
    "        'lclouds': 'lclouds-surface'\n",
    "    }\n",
    "\n",
    "    df_renombrado = df_raw.rename(columns=renombrar)\n",
    "\n",
    "    # === 5. Seleccionar la primera fila y columnas esperadas por el modelo ===\n",
    "    columnas_modelo = list(renombrar.values())\n",
    "    df_single = df_renombrado.iloc[[0]][columnas_modelo]\n",
    "\n",
    "    # === 6. Cargar el modelo entrenado ===\n",
    "    modelo = joblib.load('modelo_inundacion.pkl')\n",
    "\n",
    "    # === 7. Predecir probabilidad de inundaci√≥n ===\n",
    "    probabilidad = modelo.predict_proba(df_single)[0][1]\n",
    "    print(f\"Probabilidad de inundaci√≥n en La Maria ({lat}, {lon}): {probabilidad:.2f}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Error al consultar Windy API:\", response.status_code)\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "abcdf782-974a-41f9-a249-ae2a0c353415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad de inundaci√≥n en Danubio (4.590101, -74.224665): 0.01\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# === 1. Par√°metros de ubicaci√≥n y API ===\n",
    "# Danubio\n",
    "lat = 4.590101\n",
    "lon = -74.224665\n",
    "api_key = 'SBUdfKRVGJEmElRKmmHGGHgC4nTSzgH2'\n",
    "\n",
    "url = 'https://api.windy.com/api/point-forecast/v2'\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "parameters = ['rh', 'pressure', 'windGust', 'precip', 'cape', 'lclouds', 'convPrecip']\n",
    "levels = ['surface']\n",
    "\n",
    "payload = {\n",
    "    \"lat\": lat,\n",
    "    \"lon\": lon,\n",
    "    \"model\": \"gfs\",\n",
    "    \"parameters\": parameters,\n",
    "    \"levels\": levels,\n",
    "    \"key\": api_key\n",
    "}\n",
    "\n",
    "# === 2. Consultar Windy API ===\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "\n",
    "    # === 3. Crear DataFrame con nombres originales del API ===\n",
    "    df_raw = pd.DataFrame({k: v for k, v in data.items() if k != 'units'})\n",
    "\n",
    "    # === 4. Renombrar columnas para que coincidan con el modelo entrenado ===\n",
    "    renombrar = {\n",
    "        'precip': 'past3hprecip-surface',\n",
    "        'convPrecip': 'past3hconvprecip-surface',\n",
    "        'rh': 'rh-surface',\n",
    "        'pressure': 'pressure-surface',\n",
    "        'windGust': 'gust-surface',\n",
    "        'cape': 'cape-surface',\n",
    "        'lclouds': 'lclouds-surface'\n",
    "    }\n",
    "\n",
    "    df_renombrado = df_raw.rename(columns=renombrar)\n",
    "\n",
    "    # === 5. Seleccionar la primera fila y columnas esperadas por el modelo ===\n",
    "    columnas_modelo = list(renombrar.values())\n",
    "    df_single = df_renombrado.iloc[[0]][columnas_modelo]\n",
    "\n",
    "    # === 6. Cargar el modelo entrenado ===\n",
    "    modelo = joblib.load('modelo_inundacion.pkl')\n",
    "\n",
    "    # === 7. Predecir probabilidad de inundaci√≥n ===\n",
    "    probabilidad = modelo.predict_proba(df_single)[0][1]\n",
    "    print(f\"Probabilidad de inundaci√≥n en Danubio ({lat}, {lon}): {probabilidad:.2f}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Error al consultar Windy API:\", response.status_code)\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "67cbd906-3d1b-4ecb-be3d-74abe91bbb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Muestra simulada de entorno de riesgo moderado:\n",
      "   past3hprecip-surface  past3hconvprecip-surface  rh-surface  \\\n",
      "0              0.063238                  0.124337   91.048778   \n",
      "\n",
      "   pressure-surface  gust-surface  cape-surface  lclouds-surface  \n",
      "0      97312.773381      7.386431    155.528663        70.425789  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Simulaci√≥n de entorno de riesgo moderado\n",
    "simulacion = pd.DataFrame([{\n",
    "    'past3hprecip-surface': np.random.uniform(0.05, 0.15),         # lluvia significativa\n",
    "    'past3hconvprecip-surface': np.random.uniform(0.05, 0.15),     # convectiva activa\n",
    "    'rh-surface': np.random.uniform(85, 95),                       # humedad alta\n",
    "    'pressure-surface': np.random.uniform(97000, 98500),           # presi√≥n algo baja\n",
    "    'gust-surface': np.random.uniform(4, 8),                       # r√°fagas moderadas\n",
    "    'cape-surface': np.random.uniform(150, 400),                   # inestabilidad moderada\n",
    "    'lclouds-surface': np.random.uniform(50, 80)                   # nubosidad baja elevada\n",
    "}])\n",
    "\n",
    "print(\"‚úÖ Muestra simulada de entorno de riesgo moderado:\")\n",
    "print(simulacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "d29046ed-5aeb-4ba1-a402-13e9fd90828d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad simulada de inundaci√≥n: 0.80\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Cargar modelo entrenado\n",
    "modelo = joblib.load('modelo_inundacion.pkl')\n",
    "\n",
    "# Predecir probabilidad\n",
    "probabilidad = modelo.predict_proba(simulacion)[0][1]\n",
    "print(f\"Probabilidad simulada de inundaci√≥n: {probabilidad:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a855ff2a-93d0-470f-b255-94d0dfc36111",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "1be6335f-13b0-4e77-8802-4747931a0368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting fastapi\n",
      "  Downloading fastapi-0.120.4-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting uvicorn\n",
      "  Downloading uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\samue\\appdata\\roaming\\python\\python313\\site-packages (1.5.1)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\envs\\analiticadatos\\lib\\site-packages (2.32.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\samue\\appdata\\roaming\\python\\python313\\site-packages (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\samue\\appdata\\roaming\\python\\python313\\site-packages (1.7.1)\n",
      "Collecting starlette<0.50.0,>=0.40.0 (from fastapi)\n",
      "  Downloading starlette-0.49.3-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi)\n",
      "  Downloading pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\programdata\\anaconda3\\envs\\analiticadatos\\lib\\site-packages (from fastapi) (4.12.2)\n",
      "Collecting annotated-doc>=0.0.2 (from fastapi)\n",
      "  Downloading annotated_doc-0.0.3-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.4 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi)\n",
      "  Downloading pydantic_core-2.41.4-cp313-cp313-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from fastapi)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\programdata\\anaconda3\\envs\\analiticadatos\\lib\\site-packages (from starlette<0.50.0,>=0.40.0->fastapi) (4.7.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\programdata\\anaconda3\\envs\\analiticadatos\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.50.0,>=0.40.0->fastapi) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\programdata\\anaconda3\\envs\\analiticadatos\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.50.0,>=0.40.0->fastapi) (1.3.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\samue\\appdata\\roaming\\python\\python313\\site-packages (from uvicorn) (8.3.0)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\programdata\\anaconda3\\envs\\analiticadatos\\lib\\site-packages (from uvicorn) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\analiticadatos\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\analiticadatos\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\analiticadatos\\lib\\site-packages (from requests) (2025.7.14)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\samue\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\envs\\analiticadatos\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\samue\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\samue\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\samue\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\samue\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\analiticadatos\\lib\\site-packages (from click>=7.0->uvicorn) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\envs\\analiticadatos\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading fastapi-0.120.4-py3-none-any.whl (108 kB)\n",
      "Downloading pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
      "Downloading pydantic_core-2.41.4-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 1.6/2.0 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 7.7 MB/s eta 0:00:00\n",
      "Downloading starlette-0.49.3-py3-none-any.whl (74 kB)\n",
      "Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "Downloading annotated_doc-0.0.3-py3-none-any.whl (5.5 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-extensions, annotated-types, annotated-doc, uvicorn, typing-inspection, starlette, pydantic-core, pydantic, fastapi\n",
      "\n",
      "   ------------- -------------------------- 3/9 [uvicorn]\n",
      "   ------------- -------------------------- 3/9 [uvicorn]\n",
      "   ------------- -------------------------- 3/9 [uvicorn]\n",
      "   ------------- -------------------------- 3/9 [uvicorn]\n",
      "   ------------- -------------------------- 3/9 [uvicorn]\n",
      "   ------------- -------------------------- 3/9 [uvicorn]\n",
      "   ----------------- ---------------------- 4/9 [typing-inspection]\n",
      "   ---------------------- ----------------- 5/9 [starlette]\n",
      "   ---------------------- ----------------- 5/9 [starlette]\n",
      "   ---------------------- ----------------- 5/9 [starlette]\n",
      "   ---------------------- ----------------- 5/9 [starlette]\n",
      "   -------------------------- ------------- 6/9 [pydantic-core]\n",
      "   ------------------------------- -------- 7/9 [pydantic]\n",
      "   ------------------------------- -------- 7/9 [pydantic]\n",
      "   ------------------------------- -------- 7/9 [pydantic]\n",
      "   ------------------------------- -------- 7/9 [pydantic]\n",
      "   ------------------------------- -------- 7/9 [pydantic]\n",
      "   ------------------------------- -------- 7/9 [pydantic]\n",
      "   ------------------------------- -------- 7/9 [pydantic]\n",
      "   ------------------------------- -------- 7/9 [pydantic]\n",
      "   ------------------------------- -------- 7/9 [pydantic]\n",
      "   ------------------------------- -------- 7/9 [pydantic]\n",
      "   ------------------------------- -------- 7/9 [pydantic]\n",
      "   ------------------------------- -------- 7/9 [pydantic]\n",
      "   ------------------------------- -------- 7/9 [pydantic]\n",
      "   ------------------------------- -------- 7/9 [pydantic]\n",
      "   ------------------------------- -------- 7/9 [pydantic]\n",
      "   ----------------------------------- ---- 8/9 [fastapi]\n",
      "   ----------------------------------- ---- 8/9 [fastapi]\n",
      "   ----------------------------------- ---- 8/9 [fastapi]\n",
      "   ----------------------------------- ---- 8/9 [fastapi]\n",
      "   ----------------------------------- ---- 8/9 [fastapi]\n",
      "   ----------------------------------- ---- 8/9 [fastapi]\n",
      "   ----------------------------------- ---- 8/9 [fastapi]\n",
      "   ---------------------------------------- 9/9 [fastapi]\n",
      "\n",
      "Successfully installed annotated-doc-0.0.3 annotated-types-0.7.0 fastapi-0.120.4 pydantic-2.12.3 pydantic-core-2.41.4 starlette-0.49.3 typing-extensions-4.15.0 typing-inspection-0.4.2 uvicorn-0.38.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script uvicorn.exe is installed in 'C:\\Users\\samue\\AppData\\Roaming\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script fastapi.exe is installed in 'C:\\Users\\samue\\AppData\\Roaming\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install fastapi uvicorn joblib requests pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "35cf1da0-afb6-4aec-bce1-af4de01e5661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import requests\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# === Cargar modelo entrenado ===\n",
    "modelo = joblib.load('modelo_inundacion.pkl')\n",
    "\n",
    "# === Configuraci√≥n Windy API ===\n",
    "API_KEY = 'SBUdfKRVGJEmElRKmmHGGHgC4nTSzgH2'\n",
    "WINDY_URL = 'https://api.windy.com/api/point-forecast/v2'\n",
    "HEADERS = {'Content-Type': 'application/json'}\n",
    "PARAMS = ['rh', 'pressure', 'windGust', 'precip', 'cape', 'lclouds', 'convPrecip']\n",
    "LEVELS = ['surface']\n",
    "RENOMBRAR = {\n",
    "    'precip': 'past3hprecip-surface',\n",
    "    'convPrecip': 'past3hconvprecip-surface',\n",
    "    'rh': 'rh-surface',\n",
    "    'pressure': 'pressure-surface',\n",
    "    'windGust': 'gust-surface',\n",
    "    'cape': 'cape-surface',\n",
    "    'lclouds': 'lclouds-surface'\n",
    "}\n",
    "COLUMNAS_MODELO = list(RENOMBRAR.values())\n",
    "\n",
    "# === Entrada esperada ===\n",
    "class Ubicacion(BaseModel):\n",
    "    lat: float\n",
    "    lon: float\n",
    "\n",
    "# === Endpoint principal ===\n",
    "@app.post(\"/inundacion\")\n",
    "def predecir_inundacion(ubicacion: Ubicacion):\n",
    "    payload = {\n",
    "        \"lat\": ubicacion.lat,\n",
    "        \"lon\": ubicacion.lon,\n",
    "        \"model\": \"gfs\",\n",
    "        \"parameters\": PARAMS,\n",
    "        \"levels\": LEVELS,\n",
    "        \"key\": API_KEY\n",
    "    }\n",
    "\n",
    "    response = requests.post(WINDY_URL, json=payload, headers=HEADERS)\n",
    "    if response.status_code != 200:\n",
    "        return {\"error\": f\"API Windy fall√≥: {response.status_code}\", \"detalle\": response.text}\n",
    "\n",
    "    data = response.json()\n",
    "    df_raw = pd.DataFrame({k: v for k, v in data.items() if k != 'units'})\n",
    "    df_renombrado = df_raw.rename(columns=RENOMBRAR)\n",
    "    df_single = df_renombrado.iloc[[0]][COLUMNAS_MODELO]\n",
    "\n",
    "    probabilidad = modelo.predict_proba(df_single)[0][1]\n",
    "    return {\n",
    "        \"lat\": ubicacion.lat,\n",
    "        \"lon\": ubicacion.lon,\n",
    "        \"probabilidad_inundacion\": round(probabilidad, 4)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "6bbca1e2-4bd8-47ac-962d-1669b92d01c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Consultando La Mar√≠a ‚Üí http://127.0.0.1:8000/la_maria\n",
      "‚úÖ Resultado: [0.024, 'baja']\n",
      "\n",
      "üîç Consultando Danubio ‚Üí http://127.0.0.1:8000/danubio\n",
      "‚úÖ Resultado: [0.0654, 'baja']\n",
      "\n",
      "üîç Consultando Simulaci√≥n arriesgada ‚Üí http://127.0.0.1:8000/simulacion_arriesgada\n",
      "‚úÖ Resultado: [0.7848, 'alta']\n",
      "\n",
      "üîç Consultando Simulaci√≥n peligrosa ‚Üí http://127.0.0.1:8000/simulacion_peligrosa\n",
      "‚úÖ Resultado: [1.0, 'alta']\n",
      "\n",
      "üîç Consultando Datos Windy La Maria ‚Üí http://127.0.0.1:8000/parametros_la_maria\n",
      "‚úÖ Resultado: {'ts': 1762030800000, 'rh-surface': 93.55531662953575, 'pressure-surface': 101604.19633411664, 'gust-surface': 1.6273103457180633, 'past3hprecip-surface': 1.864375743888589e-05, 'cape-surface': 0, 'lclouds-surface': 11.906979583117108, 'past3hconvprecip-surface': 0.00017980956450086778, 'warning': 'T'}\n",
      "\n",
      "üîç Consultando Datos Windy Danubio ‚Üí http://127.0.0.1:8000/parametros_danubio\n",
      "‚úÖ Resultado: {'ts': 1762030800000, 'rh-surface': 79.52814993133342, 'pressure-surface': 101898.89967750176, 'gust-surface': 1.6673721286019814, 'past3hprecip-surface': 3.2813013092439695e-05, 'cape-surface': 27.63746825769804, 'lclouds-surface': 23.36479262672791, 'past3hconvprecip-surface': 0.00013010082705160476, 'warning': 'T'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "base_url = \"http://127.0.0.1:8000\"\n",
    "\n",
    "endpoints = {\n",
    "    \"La Mar√≠a\": \"/la_maria\",\n",
    "    \"Danubio\": \"/danubio\",\n",
    "    \"Simulaci√≥n arriesgada\": \"/simulacion_arriesgada\",\n",
    "    \"Simulaci√≥n peligrosa\": \"/simulacion_peligrosa\",\n",
    "    \"Datos Windy La Maria\": \"/parametros_la_maria\",\n",
    "    \"Datos Windy Danubio\": \"/parametros_danubio\"\n",
    "}\n",
    "\n",
    "for nombre, endpoint in endpoints.items():\n",
    "    url = base_url + endpoint\n",
    "    print(f\"üîç Consultando {nombre} ‚Üí {url}\")\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        resultado = response.json()\n",
    "        print(f\"‚úÖ Resultado: {resultado}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en {nombre}: {e}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e872a6f-1cc3-4213-85ae-66ae0cfb100a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AnaliticaDatos]",
   "language": "python",
   "name": "conda-env-AnaliticaDatos-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
